{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Com base no esquema da tabela abaixo, crie uma consulta em SQL ou uma análise em Python que responda à pergunta do usuário. Atenda às seguintes regras e instruções:\n",
    "\n",
    "------------------------------\n",
    "Esquema da Tabela:\n",
    "{schema}\n",
    "------------------------------\n",
    "\n",
    "Pergunta do Usuário:\n",
    "{question}\n",
    "\n",
    "==============================\n",
    "Caso a análise seja em Python:\n",
    "- Utilize a função run_query(query) para acessar os dados.\n",
    "- Utilize a variável 'db'; esta já foi carregada por meio da biblioteca langchain_community.utilities SQLDatabase.\n",
    "- Não use print(); armazene os resultados em variáveis para consultas posteriores.\n",
    "- Ao final, remova quaisquer variáveis que não serão utilizadas na análise.\n",
    "- Não crie dados de exemplo.\n",
    "- Certifique-se de que todas as funções necessárias sejam executadas.\n",
    "==============================\n",
    "\n",
    "Exemplo de Código:\n",
    "{exemplo}\n",
    "\n",
    "------------------------------\n",
    "Escreva a consulta (ou código) que será executado:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db_uri = \"mysql+mysqlconnector://root:0000@localhost:3306/chinook\" # Banco de dados de exemplo, disponível no github em https://github.com/lerocha/chinook-database\n",
    "db = SQLDatabase.from_uri(db_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema(_):\n",
    "    return db.get_table_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplo = '''# 1. Qual o gênero musical mais comum?\n",
    "query_genero = \"\"\"\n",
    "SELECT\n",
    "    g.Name AS NomeGenero,\n",
    "    COUNT(t.TrackId) AS NumeroDeMusicas\n",
    "FROM\n",
    "    genre g\n",
    "JOIN\n",
    "    track t ON g.GenreId = t.GenreId\n",
    "GROUP BY\n",
    "    g.Name\n",
    "ORDER BY\n",
    "    NumeroDeMusicas DESC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "genero = run_query(query_genero)\n",
    "\n",
    "del query_genero\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-2.0-flash-exp\")\n",
    "\n",
    "innitial_chain = (\n",
    "    RunnablePassthrough.assign(schema=lambda _: get_schema, exemplo=lambda _: exemplo)\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\n```\"])\n",
    "    | StrOutputParser()\n",
    "    | RunnableLambda(lambda x: (\n",
    "        x.replace(\"```sql\\n\", \"\") if \"sql\" in x else\n",
    "        x.replace(\"```python\\n\", \"\") if \"python\" in x else x\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Com base na pergunta abaixo, consulta sql e resposta sql, (obs: o usuário não consegue vê-las), escreva uma resposta em linguagem natural para o usuário:\n",
    "\n",
    "Pergunta: {question}\n",
    "Consulta: {query}\n",
    "Resposta: {response}\"\"\"\n",
    "\n",
    "prompt_response = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def run_query(query):\n",
    "    try:\n",
    "        if isinstance(query, dict):\n",
    "            query = query[\"query\"]\n",
    "        if query.strip().lower().startswith(\"select\"):\n",
    "            result = db.run(query)\n",
    "            # Verifica se há dados e converte para DataFrame\n",
    "            if result:\n",
    "                return result\n",
    "            else:\n",
    "                return None  # Retorna DataFrame vazio se não houver dados\n",
    "        else:\n",
    "            return \"Apenas consultas ou análises são permitidas.\"\n",
    "    except Exception as e:\n",
    "        return f\"Erro na execução da query: {str(e)}\"\n",
    "\n",
    "\n",
    "def run_python(python_code):\n",
    "    try:\n",
    "        globals_dict = {\"db\": db, \"pd\": pd} \n",
    "        globals_dict.update({\n",
    "            \"run_query\": lambda x: run_query(x), \n",
    "            \"SQLDatabase\": SQLDatabase\n",
    "        })\n",
    "        locals_dict = {}\n",
    "\n",
    "        # Executar o código\n",
    "        exec(python_code, globals_dict, locals_dict)\n",
    "\n",
    "        # Retornar as variáveis locais criadas\n",
    "        return locals_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erro na execução do código: {str(e)}\"\n",
    "\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=innitial_chain).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda vars: run_python(vars[\"query\"]) if \"run_query\" in vars[\"query\"] else run_query(vars[\"query\"])\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O artista com o maior número de álbuns é o Iron Maiden, com um total de 21 álbuns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_question = str(input())\n",
    "response = full_chain.invoke({\"question\":user_question})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat-with-mysql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
